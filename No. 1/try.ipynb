{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa224b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORT NECESSARY LIBRARIES\n",
    "# -----------------------------------------------------------------------------\n",
    "# Reason: We need standard data science and ML libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib  # for saving the model efficiently\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress non-critical warnings for clean output\n",
    "\n",
    "# Set style for better plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1173130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LOAD THE DATA\n",
    "# -----------------------------------------------------------------------------\n",
    "# Reason: Load the training dataset. Last column is the target (class label)\n",
    "data_path = 'fish_disease_train.csv'\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {data_path}. Please check the file path.\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape of dataset: {df.shape}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e613684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PART (a): Train a Random Forest Classifier on Fish Disease Dataset\n",
    "# Output: Save the trained model as 'model_1.pkl'\n",
    "# =============================================================================\n",
    "\n",
    "# 1. IMPORT NECESSARY LIBRARIES\n",
    "# -----------------------------------------------------------------------------\n",
    "# Reason: We need standard data science and ML libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib  # for saving the model efficiently\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress non-critical warnings for clean output\n",
    "\n",
    "# Set style for better plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# 2. LOAD THE DATA\n",
    "# -----------------------------------------------------------------------------\n",
    "# Reason: Load the training dataset. Last column is the target (class label)\n",
    "data_path = 'fish_disease_train.csv'\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {data_path}. Please check the file path.\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape of dataset: {df.shape}\")\n",
    "display(df.head())\n",
    "\n",
    "# 3. EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# 3.1 Basic information\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*50)\n",
    "df.info()\n",
    "\n",
    "# 3.2 Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 3.3 Statistical summary of numerical features\n",
    "print(\"\\nStatistical Summary (Numerical Features):\")\n",
    "display(df.describe())\n",
    "\n",
    "# 3.4 Identify feature columns and target\n",
    "# Reason: Last column is class label (0 to 9)\n",
    "feature_columns = df.columns[:-1]\n",
    "target_column = df.columns[-1]\n",
    "\n",
    "print(f\"\\nNumber of features: {len(feature_columns)}\")\n",
    "print(f\"Target column: {target_column}\")\n",
    "print(f\"Unique classes: {sorted(df[target_column].unique())}\")\n",
    "\n",
    "# 3.5 Check class distribution (Important for classification!)\n",
    "print(\"\\nClass Distribution:\")\n",
    "class_counts = df[target_column].value_counts().sort_index()\n",
    "print(class_counts)\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=df, x=target_column, order=class_counts.index, palette='viridis')\n",
    "plt.title('Distribution of Fish Disease Classes')\n",
    "plt.xlabel('Disease Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 3.6 Check for outliers using boxplots (on a subset of features for clarity)\n",
    "# Reason: Texture/color/statistical features can have extreme values\n",
    "sample_features = df[feature_columns].columns[:10]  # Show first 10 features\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(data=df[sample_features])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Boxplot of Selected Features (Checking Outliers)\")\n",
    "plt.show()\n",
    "\n",
    "# 3.7 Correlation matrix (to see multicollinearity among features)\n",
    "plt.figure(figsize=(16, 12))\n",
    "corr = df[feature_columns].corr()\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Print highly correlated pairs (>0.9)\n",
    "corr_pairs = corr.abs().unstack().sort_values(ascending=False)\n",
    "high_corr = corr_pairs[(corr_pairs > 0.9) & (corr_pairs < 1.0)]\n",
    "print(\"\\nHighly correlated feature pairs (|r| > 0.9):\")\n",
    "print(high_corr[::2])  # Avoid duplicates\n",
    "\n",
    "# 4. CREATE A CLEAN COPY FOR MODELING\n",
    "# -----------------------------------------------------------------------------\n",
    "# Reason: Keep original data untouched; work on a copy to allow safe preprocessing\n",
    "df_model = df.copy()\n",
    "\n",
    "print(f\"\\nModeling dataset created with shape: {df_model.shape}\")\n",
    "\n",
    "# 5. SEPARATE FEATURES AND TARGET\n",
    "# -----------------------------------------------------------------------------\n",
    "X = df_model[feature_columns]        # Features\n",
    "y = df_model[target_column]          # Target labels\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# 6. TRAIN-TEST SPLIT (Good practice even if not asked â€” prevents data leakage)\n",
    "# -----------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}\")\n",
    "\n",
    "# 7. TRAIN RANDOM FOREST CLASSIFIER\n",
    "# -----------------------------------------------------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Reason for chosen hyperparameters:\n",
    "# - n_estimators=300: Good balance between performance and speed\n",
    "# - max_depth=None: Let trees grow fully (RF handles overfitting via averaging)\n",
    "# - min_samples_split=2, min_samples_leaf=1: Default, works well\n",
    "# - class_weight='balanced': Helps if classes are imbalanced\n",
    "# - n_jobs=-1: Use all CPU cores\n",
    "# - random_state=42: Reproducibility\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced',   # Important for potentially imbalanced classes\n",
    "    max_features='sqrt',       # Standard for classification\n",
    "    bootstrap=True\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest Classifier...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 8. QUICK EVALUATION ON VALIDATION SET (Optional but recommended)\n",
    "# -----------------------------------------------------------------------------\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION PERFORMANCE (Random Forest - model_1)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Optional: Plot confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('Confusion Matrix - Validation Set')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# 9. SAVE THE TRAINED MODEL AS model_1.pkl\n",
    "# -----------------------------------------------------------------------------\n",
    "model_filename = 'model_1.pkl'\n",
    "joblib.dump(rf_model, model_filename)\n",
    "\n",
    "print(f\"\\nRandom Forest model trained and saved as '{model_filename}'\")\n",
    "print(f\"Model uses {rf_model.n_features_in_} features and {rf_model.n_classes_} classes.\")\n",
    "\n",
    "# Optional: Verify model can be loaded\n",
    "loaded_model = joblib.load(model_filename)\n",
    "print(\"Model saved and loading verified successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
